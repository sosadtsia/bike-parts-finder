---
description: Web Scraping Guidelines
globs: pkg/scraping/**,cmd/scraper/**,pkg/models/**
alwaysApply: true
---

# Web Scraping Guidelines

## Ethical Scraping
- Follow robots.txt rules
- Implement rate limiting to avoid overloading target sites
- Include identifying information in User-Agent
- Cache results to minimize requests
- Avoid scraping during high-traffic periods

## Technical Implementation
- Use Colly library for scraping
- Implement robust error handling
- Handle different response types
- Support proxy rotation if needed
- Implement retries with backoff for failed requests

## Data Processing
- Validate and clean scraped data
- Handle missing data gracefully
- Normalize data before storage
- Log scraping statistics

## Architecture
- Use Kafka for handling scrape requests and results
- Process scrape jobs asynchronously
- Use a pipeline approach for data processing
- Separate scraping logic from business logic
